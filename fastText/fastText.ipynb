{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import torch\n",
    "import scipy\n",
    "import scipy.spatial\n",
    "import fasttext\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_size = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add other fastText pre-trained models url\n",
    "# https://github.com/facebookresearch/fastText/blob/master/docs/pretrained-vectors.md\n",
    "# https://towardsdatascience.com/super-easy-way-to-get-sentence-embedding-using-fasttext-in-python-a70f34ac5b7c\n",
    "\n",
    "# word_embedders.get_fasttext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "--- 6.864881992340088 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sister\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "sentence_embedding = sister.MeanEmbedding(lang=\"en\")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"I am a dog.\"\n",
    "vector = sentence_embedding(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_description_path = '../final_proj/cleandata/description.csv'\n",
    "ground_truth_similar_books_csv = \"cleandata/similar_books.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_size = 300\n",
    "df_similar_books_GT = pd.read_csv(ground_truth_similar_books_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_set_similar_books_GT():\n",
    "    from random import seed\n",
    "    from random import randint\n",
    "    seed(10)\n",
    "    \n",
    "    similar_books_GT_test_dict = {}\n",
    "    count = 0\n",
    "    i = 0\n",
    "    while count < 300:\n",
    "#         i = randint(0, len(df_similar_books_GT)) # add the randomness of the test set.\n",
    "        temp_similar_books = df_similar_books_GT.iloc[i]['similar_books']\n",
    "        if temp_similar_books != \"[]\":\n",
    "            book_id = df_similar_books_GT.iloc[i]['book_id']\n",
    "            # preprocess the similar books GT\n",
    "            temp_similar_books = temp_similar_books.replace(\"[\", \"\")\n",
    "            temp_similar_books = temp_similar_books.replace(\"]\", \"\")\n",
    "            temp_similar_books = temp_similar_books.replace(\"'\", \"\")\n",
    "            temp_similar_books = [int(j.strip()) for j in temp_similar_books.split(\",\")]\n",
    "            similar_books_GT_test_dict[book_id] = temp_similar_books\n",
    "            count = count+1\n",
    "        i = i+1\n",
    "    return similar_books_GT_test_dict\n",
    "# similar_books_GT_test_dict= get_test_set_similar_books_GT()\n",
    "# similar_books_GT_test_dict[29245852]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Similarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_similarity_score(text1,text2):\n",
    "    embedding1 = sentence_embedding(text1)\n",
    "    embedding2 = sentence_embedding(text2)\n",
    "    distance = scipy.spatial.distance.cosine(embedding1, embedding2)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Description table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_description = pd.read_csv(books_description_path)\n",
    "df_description = df_description.replace(np.nan, \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5333265</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1333909</td>\n",
       "      <td>Anita Diamant's international bestseller \"The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7327624</td>\n",
       "      <td>Omnibus book club edition containing the Ladie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6066819</td>\n",
       "      <td>Addie Downs and Valerie Adler were eight when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>287140</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id                                        description\n",
       "0  5333265                                                   \n",
       "1  1333909  Anita Diamant's international bestseller \"The ...\n",
       "2  7327624  Omnibus book club edition containing the Ladie...\n",
       "3  6066819  Addie Downs and Valerie Adler were eight when ...\n",
       "4   287140                                                   "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_description.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_description(book_id):\n",
    "    return df_description[df_description['book_id'] == book_id]['description'].to_string(index=False).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import book-to-book Similar Set Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not using it for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_n=20\n",
    "\n",
    "similar_books_GT_test_dict = get_test_set_similar_books_GT()\n",
    "accuracy_set = [] \n",
    "accuracy_closest_5_set = []\n",
    "\n",
    "for book_id in similar_books_GT_test_dict.keys():\n",
    "    distances = []\n",
    "    book_description = get_book_description(book_id)\n",
    "    if book_description == '':\n",
    "        continue\n",
    "    for similar_book_ids in similar_books_GT_test_dict[book_id]:\n",
    "        similar_book_description = get_book_description(similar_book_ids)\n",
    "        if book_description != '' and similar_book_description!= '':\n",
    "            distance  = generate_similarity_score(book_description, similar_book_description)\n",
    "            distances.append(distance)\n",
    "        if len(distances)>20:\n",
    "            break\n",
    "            \n",
    "    distances.sort()\n",
    "    distances_closet_5 = distances[:min(5,len(distances))]\n",
    "    \n",
    "    accuracy = 1 - sum(distances)/len(distances)\n",
    "    accuracy_closest_5 = 1 - sum(distances_closet_5)/len(distances_closet_5)\n",
    "    \n",
    "    accuracy_set.append(accuracy)\n",
    "    accuracy_closest_5_set.append(accuracy_closest_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = sum(accuracy_set)/len(accuracy_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_closest_5_set = sum(accuracy_closest_5_set)/len(accuracy_closest_5_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.751763024560444"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7866675584652593"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_closest_5_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "similar_books_GT_test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_set_similar_books_GT():\n",
    "    from random import seed\n",
    "    from random import randint\n",
    "    seed(10)\n",
    "    \n",
    "    similar_books_GT_test_dict = {}\n",
    "    \n",
    "    for _ in range(test_set_size):\n",
    "        i = randint(0, len(df_similar_books_GT)) # add the randomness of the test set.\n",
    "        temp_similar_books = df_similar_books_GT.iloc[i]['similar_books']\n",
    "        if temp_similar_books != \"[]\":\n",
    "            book_id = df_similar_books_GT.iloc[i]['book_id']\n",
    "            # preprocess the similar books GT\n",
    "            temp_similar_books = temp_similar_books.replace(\"[\", \"\")\n",
    "            temp_similar_books = temp_similar_books.replace(\"]\", \"\")\n",
    "            temp_similar_books = temp_similar_books.replace(\"'\", \"\")\n",
    "            temp_similar_books = [int(j.strip()) for j in temp_similar_books.split(\",\")]\n",
    "            similar_books_GT_test_dict[book_id] = temp_similar_books\n",
    "    return similar_books_GT_test_dict\n",
    "\n",
    "similar_books_GT_test_dict= get_test_set_similar_books_GT()\n",
    "similar_books_GT_test_dict[29245852]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_flag = \"fastTest\"\n",
    "def get_accuracy(model_flag):\n",
    "    test_set_accuracy = 0\n",
    "    test_set_accuracy_closest_5 = 0\n",
    "    count_iteration = 0\n",
    "    # get the test set description\n",
    "    for book_id, similar_books_id_list in similar_books_GT_test_dict.items():\n",
    "        description_book, description_similar_books_list = get_description_for_book_and_similar_books(book_id, similar_books_id_list)\n",
    "        # print(description_book)\n",
    "        # print(len(description_similar_books_list))\n",
    "        if len(description_book) < 20: # filter out those with less description to keep the model accurate\n",
    "            continue\n",
    "        \n",
    "        # fastTestt\n",
    "        if model_flag == \"fastTest\":\n",
    "            temp_accuracy, temp_accuracy_closest_5 = generate_embeddings_and_compute_ranked_distance(description_book, description_similar_books_list, print_mode=False)\n",
    "      \n",
    "            if temp_accuracy > 0: # filter out input book description is null or meaningless\n",
    "                test_set_accuracy += temp_accuracy\n",
    "                test_set_accuracy_closest_5 += temp_accuracy_closest_5\n",
    "                count_iteration += 1\n",
    "\n",
    "    test_set_accuracy /= count_iteration\n",
    "    test_set_accuracy_closest_5 /= count_iteration\n",
    "    \n",
    "    return test_set_accuracy, test_set_accuracy_closest_5\n",
    "\n",
    "test_set_accuracy, test_set_accuracy_closest_5 = get_accuracy(model_flag)\n",
    "print('---------------------------------')\n",
    "print('test_set_accuracy: ', test_set_accuracy)\n",
    "print('test_set_accuracy_closest_5: ', test_set_accuracy_closest_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('description_embedding_fasttext.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['book_id', 'embedding'])\n",
    "    lines_with_error_count = 0\n",
    "    \n",
    "    with open(file_path) as file:\n",
    "        next(file)\n",
    "        for line in file:\n",
    "            try:\n",
    "#                 data = line.split()\n",
    "#                 book_id = data[1]\n",
    "#                 embedding = sentence_embedding(data[2])\n",
    "#                 writer.writerow([book_id, embeddingii])\n",
    "                data = line.split()\n",
    "                book_id = data[0]\n",
    "                if book_id == 287141:\n",
    "                    a = (data[1])\n",
    "                break\n",
    "            except:\n",
    "                lines_with_error_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path) as file:\n",
    "    next(file)\n",
    "    for line in file:\n",
    "        try:\n",
    "#                 data = line.split()\n",
    "#                 book_id = data[1]\n",
    "#                 embedding = sentence_embedding(data[2])\n",
    "#                 writer.writerow([book_id, embeddingii])\n",
    "            data = line.split('')\n",
    "            book_id = data[0]\n",
    "            a = data[1]\n",
    "            break\n",
    "        except:\n",
    "            lines_with_error_count += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Similarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_with_error_count\n",
    "scipy.spatial.distance.cosine(vector, vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =  generate_similarity_score(vector,vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format\n",
    "\n",
    "https://fasttext.cc/docs/en/english-vectors.html\n",
    "\n",
    "The first line of the file contains the number of words in the vocabulary and the size of the vectors. Each line contains a word followed by its vectors, like in the default fastText text format. Each value is space separated. Words are ordered by descending frequency. These text models can easily be loaded in Python using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = map(float, tokens[1:])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_vectors('pretrained/crawl-300d-2M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
